{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:34:59.836420Z",
     "start_time": "2025-03-01T06:34:57.790394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader import label_str2int_dict\n",
    "\n",
    "rationale_names = {'td','itc','img','cs'}\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "os.chdir('/media/shared_d/lyq/DataSet/FakeNews/twitter')\n",
    "print(os.getcwd())\n",
    "\n"
   ],
   "id": "c5ecb7a743d22bd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lyq/PycharmProjects/QwenVLRationaleGenerate/data/twitter\n",
      "/media/shared_d/lyq/DataSet/FakeNews/twitter\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:01.522427Z",
     "start_time": "2025-03-01T06:35:01.464136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('twitter.csv',encoding='utf-8')\n",
    "df.rename(columns={'post_id':'source_id','post_text':'content'},inplace=True)\n",
    "# content,label,image_id,source_id,split,td_rationale,td_pred,td_acc,cs_rationale,cs_pred,cs_acc\n",
    "df['label'] = df['label'].apply(lambda x: label_str2int_dict[x])\n",
    "df['split'] = np.nan\n",
    "df = df[['source_id','content','label','split','image_id']]\n",
    "df.columns"
   ],
   "id": "3f8f751cfa7a603d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_id', 'content', 'label', 'split', 'image_id'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:05.314679Z",
     "start_time": "2025-03-01T06:35:03.767973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for rationale_name in rationale_names:\n",
    "    rationale_df = pd.read_csv(f'{rationale_name}.csv')\n",
    "    rationale_df = rationale_df.dropna(subset=['authenticity','reason'])\n",
    "    df = df.merge(rationale_df,on='source_id',how='left')\n",
    "    df = df.rename(columns={\n",
    "        'authenticity':f'{rationale_name}_pred',\n",
    "        'reason': f'{rationale_name}_rationale',\n",
    "    })\n",
    "    df = df.dropna(subset=[f'{rationale_name}_pred',f'{rationale_name}_rationale'])\n",
    "    df[f'{rationale_name}_pred'] = df[f'{rationale_name}_pred'].apply(lambda x: label_str2int_dict[x])\n",
    "    df[f'{rationale_name}_acc'] = df.apply(lambda x : int(x[f'{rationale_name}_pred']==x['label']) ,axis=1)\n",
    "    print(df.columns)\n",
    "  \n",
    "df\n",
    "    "
   ],
   "id": "d219c5ba2378b7d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'content', 'label', 'split', 'image_id', 'img_pred',\n",
      "       'img_rationale', 'img_acc'],\n",
      "      dtype='object')\n",
      "Index(['source_id', 'content', 'label', 'split', 'image_id', 'img_pred',\n",
      "       'img_rationale', 'img_acc', 'cs_pred', 'cs_rationale', 'cs_acc'],\n",
      "      dtype='object')\n",
      "Index(['source_id', 'content', 'label', 'split', 'image_id', 'img_pred',\n",
      "       'img_rationale', 'img_acc', 'cs_pred', 'cs_rationale', 'cs_acc',\n",
      "       'itc_pred', 'itc_rationale', 'itc_acc'],\n",
      "      dtype='object')\n",
      "Index(['source_id', 'content', 'label', 'split', 'image_id', 'img_pred',\n",
      "       'img_rationale', 'img_acc', 'cs_pred', 'cs_rationale', 'cs_acc',\n",
      "       'itc_pred', 'itc_rationale', 'itc_acc', 'td_pred', 'td_rationale',\n",
      "       'td_acc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                source_id                                            content  \\\n",
       "0      325145334739267584  PIC: Comparison of #Boston suspect Sunil Tripa...   \n",
       "1      325152091423248385  I'm not completely convinced that it's this Su...   \n",
       "2      324315545572896768  4chan and the bombing. just throwing it out th...   \n",
       "3      324581777614180352  4chan thinks they found pictures of the bomber...   \n",
       "4      324665423956176896  Ola ke ase, investigando las bombas de Boston ...   \n",
       "...                   ...                                                ...   \n",
       "14190  700662094107119616  14 children! 14 different fathers! All of them...   \n",
       "14191  700638809155710977  Meet The Woman Who Has Given Birth To 14 Child...   \n",
       "14192  700618091886047232  RT @Viasat1Ghana: Woman, 36, gives birth to 14...   \n",
       "14193  700569502874992640  Woman Breaks World Record With 14 Children fro...   \n",
       "14194  700569797545881600  RT @Abiola_j360ent: Woman Breaks World Record ...   \n",
       "\n",
       "       label  split             image_id  img_pred  \\\n",
       "0          1    NaN       boston_fake_23         1   \n",
       "1          1    NaN       boston_fake_34         1   \n",
       "2          1    NaN       boston_fake_15         1   \n",
       "3          1    NaN       boston_fake_08         1   \n",
       "4          1    NaN       boston_fake_35         1   \n",
       "...      ...    ...                  ...       ...   \n",
       "14190      1    NaN  woman_14_children_1         0   \n",
       "14191      1    NaN  woman_14_children_1         0   \n",
       "14192      1    NaN  woman_14_children_1         0   \n",
       "14193      1    NaN  woman_14_children_2         0   \n",
       "14194      1    NaN  woman_14_children_2         0   \n",
       "\n",
       "                                           img_rationale  img_acc  cs_pred  \\\n",
       "0       1. Image source\\n\\n- **Watermark or logo**: T...        1        1   \n",
       "1       1. Source of images\\n- **Watermarks or logos*...        1        1   \n",
       "2       1. Source of images\\n- **Watermarks or logos*...        1        1   \n",
       "3       1. Source of the image\\n- **Watermarks or log...        1        1   \n",
       "4       1. Image source\\n\\n- **Watermarks or logos**:...        1        1   \n",
       "...                                                  ...      ...      ...   \n",
       "14190   1. Source of the image\\n- **Watermarks or log...        0        1   \n",
       "14191   1. Source of images\\n- **Watermarks or logos*...        0        1   \n",
       "14192   1. Source of the image\\n- **Watermarks or log...        0        1   \n",
       "14193   1. Source of the image\\n- **Watermarks or log...        0        1   \n",
       "14194   1. Source of images\\n- **Watermarks or logos*...        0        1   \n",
       "\n",
       "                                            cs_rationale  cs_acc  itc_pred  \\\n",
       "0       Plausibility: The message suggests a comparis...       1         0   \n",
       "1       Plausibility: The message suggests doubt abou...       1         0   \n",
       "2       Plausibility: The message is vague and lacks ...       1         0   \n",
       "3       Plausibility: Claims from anonymous sources l...       1         1   \n",
       "4       Plausibility: The message is written in a mix...       1         0   \n",
       "...                                                  ...     ...       ...   \n",
       "14190   Plausibility: The claim that a woman has 14 c...       1         1   \n",
       "14191   Plausibility: While it is possible for a woma...       1         0   \n",
       "14192   Plausibility: While it is possible for a woma...       1         1   \n",
       "14193   Plausibility: While it is biologically possib...       1         1   \n",
       "14194   Plausibility: While it is theoretically possi...       1         1   \n",
       "\n",
       "                                           itc_rationale  itc_acc  td_pred  \\\n",
       "0       1. **Accident**: The image contains surveilla...        0        1   \n",
       "1       1. **Incident**: The news article is about a ...        0        1   \n",
       "2       1. **Incident**: The picture shows a crowd of...        0        1   \n",
       "3       1. **Accident**: The picture shows two indivi...        1        1   \n",
       "4       1. **Incident**: The picture shows a crowd of...        0        1   \n",
       "...                                                  ...      ...      ...   \n",
       "14190   1. **Incident**: The image shows a couple hol...        1        1   \n",
       "14191   1. **Incident**: The news article is about a ...        0        1   \n",
       "14192   1. **Accident**: The image shows a woman hold...        1        1   \n",
       "14193   1. **Accident**: The news states that a woman...        1        1   \n",
       "14194   1. **Accident**: The news claims that a woman...        1        1   \n",
       "\n",
       "                                            td_rationale  td_acc  \n",
       "0       1. The message suggests a comparison between ...       1  \n",
       "1       1. The message is a tweet expressing doubt ab...       1  \n",
       "2       1. The message is extremely brief and lacks c...       1  \n",
       "3       1. Source: The source of the message is 4chan...       1  \n",
       "4       1. Language: The message is written in a mix ...       1  \n",
       "...                                                  ...     ...  \n",
       "14190   1. The claim that a woman has 14 children wit...       1  \n",
       "14191   1. Sensationalism: The headline is highly sen...       1  \n",
       "14192   1. **Source**: The source of the tweet is Via...       1  \n",
       "14193   1. **Source**: The source of the message is n...       1  \n",
       "14194   1. **Source**: The tweet is retweeted from an...       1  \n",
       "\n",
       "[14195 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_pred</th>\n",
       "      <th>img_rationale</th>\n",
       "      <th>img_acc</th>\n",
       "      <th>cs_pred</th>\n",
       "      <th>cs_rationale</th>\n",
       "      <th>cs_acc</th>\n",
       "      <th>itc_pred</th>\n",
       "      <th>itc_rationale</th>\n",
       "      <th>itc_acc</th>\n",
       "      <th>td_pred</th>\n",
       "      <th>td_rationale</th>\n",
       "      <th>td_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325145334739267584</td>\n",
       "      <td>PIC: Comparison of #Boston suspect Sunil Tripa...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boston_fake_23</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Image source\\n\\n- **Watermark or logo**: T...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: The message suggests a comparis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. **Accident**: The image contains surveilla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1. The message suggests a comparison between ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325152091423248385</td>\n",
       "      <td>I'm not completely convinced that it's this Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boston_fake_34</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Source of images\\n- **Watermarks or logos*...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: The message suggests doubt abou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. **Incident**: The news article is about a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1. The message is a tweet expressing doubt ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324315545572896768</td>\n",
       "      <td>4chan and the bombing. just throwing it out th...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boston_fake_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Source of images\\n- **Watermarks or logos*...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: The message is vague and lacks ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. **Incident**: The picture shows a crowd of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1. The message is extremely brief and lacks c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324581777614180352</td>\n",
       "      <td>4chan thinks they found pictures of the bomber...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boston_fake_08</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Source of the image\\n- **Watermarks or log...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: Claims from anonymous sources l...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Accident**: The picture shows two indivi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Source: The source of the message is 4chan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324665423956176896</td>\n",
       "      <td>Ola ke ase, investigando las bombas de Boston ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boston_fake_35</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Image source\\n\\n- **Watermarks or logos**:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: The message is written in a mix...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. **Incident**: The picture shows a crowd of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Language: The message is written in a mix ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14190</th>\n",
       "      <td>700662094107119616</td>\n",
       "      <td>14 children! 14 different fathers! All of them...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. Source of the image\\n- **Watermarks or log...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: The claim that a woman has 14 c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Incident**: The image shows a couple hol...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. The claim that a woman has 14 children wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14191</th>\n",
       "      <td>700638809155710977</td>\n",
       "      <td>Meet The Woman Who Has Given Birth To 14 Child...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. Source of images\\n- **Watermarks or logos*...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: While it is possible for a woma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. **Incident**: The news article is about a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1. Sensationalism: The headline is highly sen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14192</th>\n",
       "      <td>700618091886047232</td>\n",
       "      <td>RT @Viasat1Ghana: Woman, 36, gives birth to 14...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1. Source of the image\\n- **Watermarks or log...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: While it is possible for a woma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Accident**: The image shows a woman hold...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Source**: The source of the tweet is Via...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14193</th>\n",
       "      <td>700569502874992640</td>\n",
       "      <td>Woman Breaks World Record With 14 Children fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman_14_children_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1. Source of the image\\n- **Watermarks or log...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: While it is biologically possib...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Accident**: The news states that a woman...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Source**: The source of the message is n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14194</th>\n",
       "      <td>700569797545881600</td>\n",
       "      <td>RT @Abiola_j360ent: Woman Breaks World Record ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman_14_children_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1. Source of images\\n- **Watermarks or logos*...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Plausibility: While it is theoretically possi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Accident**: The news claims that a woman...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1. **Source**: The tweet is retweeted from an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14195 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:08.895736Z",
     "start_time": "2025-03-01T06:35:08.011551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"before filtering : {df.shape[0]}  real data :{(df['label']==1).sum()} fake data: {(df['label']==0).sum()}\")\n",
    "\n",
    "def valid_row(row):\n",
    "    condition = [(row['label'] in [0,1]),(row['content'] is not None and len(row['content'])>0)]\n",
    "    for rationale_name in rationale_names:\n",
    "        condition.extend(\n",
    "            [(row[f'{rationale_name}_pred'] in [0,1,2]),\n",
    "             (row[f'{rationale_name}_acc'] in [0,1]),\n",
    "             (row[f'{rationale_name}_rationale'] is not None and len(row[f'{rationale_name}_rationale']) > 0)]\n",
    "        )\n",
    "    return all(condition)\n",
    "\n",
    "df = df[df.apply(valid_row,axis=1)]\n",
    "print(f\"after filtering : {df.shape[0]}  real data :{(df['label']==1).sum()} fake data: {(df['label']==0).sum()}\")"
   ],
   "id": "b010666f394d5f7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering : 14195  real data :7763 fake data: 6432\n",
      "after filtering : 14195  real data :7763 fake data: 6432\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:11.634940Z",
     "start_time": "2025-03-01T06:35:10.811964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Util import cal_rationale_metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "\n",
    "for r_name in rationale_names:\n",
    "    pred = df[r_name+ \"_pred\"].tolist()\n",
    "    label = df['label'].tolist()\n",
    "    print(f'{r_name}: {cal_rationale_metrics(pred,label)}')\n",
    "    "
   ],
   "id": "6bbe69420ea996dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: {'acc': 0.7779499823881648, 'recall': 0.7866563241213743, 'recall_real': 0.8795087064676617, 'recall_fake': 0.693803941775087, 'precision': 0.7891705847453954, 'precision_real': 0.7041324371421459, 'precision_fake': 0.8742087323486447, 'f1_macro': 0.7778690211915741, 'f1_real': 0.7821097746439928, 'f1_fake': 0.7736282677391554}\n",
      "cs: {'acc': 0.6779852060584713, 'recall': 0.6724966301911799, 'recall_real': 0.6139614427860697, 'recall_fake': 0.7310318175962901, 'precision': 0.6748845163901629, 'precision_real': 0.6541328474407818, 'precision_fake': 0.695636185339544, 'f1_macro': 0.6731528887955175, 'f1_real': 0.6334108589301468, 'f1_fake': 0.7128949186608882}\n",
      "itc: {'acc': 0.7384994716449454, 'recall': 0.7553726280359121, 'recall_real': 0.9353233830845771, 'recall_fake': 0.5754218729872472, 'precision': 0.7804272906985664, 'precision_real': 0.6460481099656358, 'precision_fake': 0.9148064714314971, 'f1_macro': 0.7353480453988472, 'f1_real': 0.7642276422764228, 'f1_fake': 0.7064684485212716}\n",
      "td: {'acc': 0.6865797816132441, 'recall': 0.6794081128878344, 'recall_real': 0.6029228855721394, 'recall_fake': 0.7558933402035296, 'precision': 0.6842472037243117, 'precision_real': 0.671747791442924, 'precision_fake': 0.6967466160056993, 'f1_macro': 0.6802965557120234, 'f1_real': 0.6354772634166326, 'f1_fake': 0.7251158480074142}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:29.922615Z",
     "start_time": "2025-03-01T06:35:29.878192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_data(df, train_ratio=0.8, valid_ratio=0.1, random_state=None, stratify_col=None):\n",
    "    \"\"\"\n",
    "    将 pandas DataFrame 划分为训练集、验证集和测试集。\n",
    "\n",
    "    参数:\n",
    "        df (pd.DataFrame): 包含所有数据的 pandas DataFrame。\n",
    "        train_ratio (float): 训练集所占比例，默认为 0.8。\n",
    "        valid_ratio (float): 验证集所占比例，默认为 0.1。\n",
    "        random_state (int, RandomState instance or None): 控制随机抽样的种子，默认为 None。\n",
    "        stratify_col (str or None): 如果不为 None，则数据将按照指定列进行分层抽样，默认为 None。\n",
    "\n",
    "    返回:\n",
    "        tuple: 包含训练集、验证集和测试集的元组。\n",
    "               每个集合都是原始 DataFrame 的一部分，包含所有原始列。\n",
    "    \"\"\"\n",
    "    # 计算测试集的比例\n",
    "    test_ratio = 1 - train_ratio - valid_ratio\n",
    "    if test_ratio <= 0:\n",
    "        raise ValueError(\"The sum of train_ratio and valid_ratio must be less than 1.\")\n",
    "    \n",
    "    # 分层抽样的依据列（如果指定了）\n",
    "    stratify = df[stratify_col] if stratify_col else None\n",
    "    \n",
    "    # 第一步：先从全部数据中划分出测试集\n",
    "    remaining_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=test_ratio , \n",
    "        random_state=random_state, \n",
    "        shuffle=True,\n",
    "        stratify=stratify\n",
    "    )\n",
    "    \n",
    "    # 更新分层抽样的依据列（如果指定了）\n",
    "    stratify_remaining = remaining_df[stratify_col] if stratify_col else None\n",
    "    \n",
    "    # 第二步：从剩余的数据中划分出训练集和验证集\n",
    "    train_df, valid_df = train_test_split(\n",
    "        remaining_df,\n",
    "        test_size=valid_ratio / (train_ratio + valid_ratio),\n",
    "        random_state=random_state,\n",
    "        shuffle=True,\n",
    "        stratify=stratify_remaining\n",
    "    )\n",
    "\n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "\n",
    "train_df,valid_df,test_df = split_data(df,train_ratio=0.6,valid_ratio=0.2,random_state=666,stratify_col='label')\n",
    "\n",
    "\n",
    "train_df.shape[0],valid_df.shape[0],test_df.shape[0]"
   ],
   "id": "206c383a79937443",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8517, 2839, 2839)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T06:35:33.964624Z",
     "start_time": "2025-03-01T06:35:31.455897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df.to_csv('twitter_llm_rationales.csv',index=False)\n",
    "train_df.to_csv('train.csv',index=False)\n",
    "valid_df.to_csv('val.csv',index=False)\n",
    "test_df.to_csv('test.csv',index=False)"
   ],
   "id": "cae981c3368fdf83",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
